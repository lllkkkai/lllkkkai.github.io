---
layout: post
title: Redis合订版
---
## 基础题
1. 缓存雪崩：大量缓存同时失效，请求直接打到数据库
解决方案：
- 设置随机过期时间
- 本地缓存降级
- 热点数据永不过期（redis内存持续增长，会触发内存淘汰策略，极端情况出现OOM）
- 集群部署，避免单点故障

2. 缓存击穿：热点key过期，大量请求直接访问数据库
解决方案：
- 热点数据永不过期
- 互斥锁
- 提前更新缓存

3. 缓存穿透：查询不存在的数据，请求直接打到数据库
- 缓存空值（设置较短过期时间）
- 布隆过滤器（一个位图+多个哈希函数）
- 请求参数校验
- 接口限流

4. key值自动过期是怎么实现的？
- 过期字典（存储所有键值对，存储键的过期时间）
- 惰性删除（每次访问key时检查，执行命令前自动调用）
- 定期删除（每次随机检查key，定期删除处理）

5. 内存淘汰策略：
- LRU

6. 如何更新redis的缓存（缓存于数据库的一致性）
- 先更新数据库，再更新缓存（适用一般情况，读多写少的场景，配合延迟双删解决并发问题）
- 高一致性考虑分布式锁
- 高并发写入考虑先更新缓存异步更新数据库
- 缓存过期时间作为兜底方案

7. 大key和热key问题

### (1) 大 Key (Big Key)
**定义**：
- Value 占用内存过大（如 String超过 10KB）。
- 集合元素过多（如 Hash, List, Set 元素数量超过 5000 个）。

**危害**：
- **阻塞主线程**：Redis 单线程模型，处理大 Key 的读写、序列化/反序列化、扩容/缩容耗时久，导致其他命令阻塞。
- **网络阻塞**：每次获取大 Key 产生的网络流量巨大，可能占满带宽。
- **删除阻塞**：`DEL` 大 Key 时可能造成长时间阻塞（建议用 `UNLINK` 异步删除）。
- **内存倾斜**：在集群模式下，某个分片内存占用过高。

**如何发现**：
- `redis-cli --bigkeys`：扫描并统计大 Key。
- RDB 分析工具（rdb-tools）：离线分析 RDB 文件。
- 监控告警：监控网络带宽异常或慢查询日志。

**解决方案**：
- **拆分**：将一个大 Hash 拆分为多个小 Hash（如 `User:100` 拆为 `User:100:Basic`, `User:100:Detail`）。
- **压缩**：对 value 进行压缩（如 Snappy, Gzip）后再存。
- **定期清理**：避免 List/Set 无限增长，设置过期时间或定期 `LTRIM`。
- **避免全量查询**：禁止 `HGETALL`, `SMEMBERS`，改用 `HSCAN`, `SSCAN`。

### (2) 热 Key (Hot Key)
**定义**：
- 某个 Key 的访问 QPS 极高（如每秒几万次），导致流量集中打在一个 Redis 节点上。
- 常见场景：秒杀商品、微博热搜、突发新闻。

**危害**：
- **节点过载**：单节点 CPU 飙升，导致该分片响应变慢甚至宕机。
- **缓存击穿风险**：一旦热 Key 所在节点宕机，巨大流量会直接打到数据库。
- **集群不均**：流量倾斜，其他节点空闲，热点节点不堪重负。

**如何发现**：
- **客户端统计**：在业务代码中进行计数统计（有侵入性）。
- **代理层统计**：在 Twemproxy / Codis / Proxy 层进行统计。
- **Redis 自带命令**：`redis-cli --hotkeys`（需开启 LFU 淘汰策略）。
- `MONITOR` 命令：短对抓取分析（生产环境慎用，有性能影响）。

**解决方案**：
- **本地缓存（多级缓存）**：
  - 将热 Key 加载到应用服务器的本地内存（如 Guava Cache, Caffeine）。
  - 请求优先读本地，不仅快，而且原本打到 Redis 的 N 次请求变为 0 次。
- **热 Key 拆分（副本策略）**：
  - 将 `hot_key` 复制为 `hot_key_1`, `hot_key_2` ... `hot_key_N`，存储在不同的节点上。
  - 客户端请求时随机访问一个副本，将流量分散到多个 Redis 节点。
- **读写分离**：利用主从复制，让多个从节点分担读流量（注意主从延迟问题）。8. 数据分片
- 一致性哈希（解决数据倾斜问题）
- 虚拟节点（解决热点key问题）

9. 线程模型



## 分布式锁

为什么redis可以被作为分布式锁使用？

### 分布式锁的本质

在分布式系统中，多个节点可能同时尝试修改同一份资源（比如同一笔订单、同一个库存记录）。
分布式锁的目标是确保：

> 同一时刻只有一个节点能成功获得锁，从而独占访问资源。

（Set if Not Exists）
SET key value [EX seconds] [PX milliseconds] [NX|XX]
  使用 `SET key value NX PX timeout` 命令实现分布式锁：
  - `NX`：只有当键不存在时才设置。
  - `PX`：设置键的过期时间，防止死锁。
  解锁：使用lua脚本释放锁保证原子性（执行lua脚本会阻塞其他命令，且不可中断）
```lua
-- 这个脚本在Redis中是完全原子的执行
if redis.call('get', KEYS[1]) == ARGV[1] then
    return redis.call('del', KEYS[1])
else
    return 0
end
```
### 不足与解决方案
1. 锁过期但业务未完成时，可能导致锁被其他客户端获取。
> 解决方案：定时续期机制（看门狗）。

2. 主从复制导致的锁失效问题
> 解决方案：
> - 使用 Redlock 算法（多个独立的 Redis 节点）
> - 等待主从同步完成后再返回（WAIT 命令）

3. 网络分区问题
> 解决方案：
> - 使用 Redlock 算法
> - 合理设置网络超时时间
> - 配合业务补偿机制

4. 时钟漂移问题
> 解决方案：
> - 使用相对时间而不是绝对时间
> - 定期同步服务器时间
> - 时间容差要大于可能的时钟漂移

5. 客户端崩溃导致锁无法释放
> 解决方案：
> - 设置合理的过期时间
> - 使用守护线程自动续期
> - 保证锁的可重入性

## 热点问题（Hot Key）

当某个 Key 的访问流量（QPS）远远超出其他 Key，导致大量请求流量集中在某一个 Redis 实例（分片）上时，就会产生**热点 Key 问题**。

### 1. 产生原因
- **突发热点事件**：如微博热搜、秒杀活动、突发新闻。
- **业务设计缺陷**：全量数据或者大范围数据聚合在少数几个 Key 中。

### 2. 带来的危害
- **流量倾斜**：该特定分片负载过高（CPU/带宽打满），而其他分片空闲。
- **单点故障**：可能导致该分片宕机，引发缓存击穿，请求透传数据库，导致数据库雪崩。

### 3. 如何发现热 Key？
- **Redis 4.0+**：使用 `redis-cli --hotkeys` 命令（需将 `maxmemory-policy` 设置为 LFU 算法）。
- **业务端监控**：在客户端 SDK 中对 Key 进行计数采样，上报热点。
- **代理层监控**：如果是 Twemproxy 或 Codis 架构，可以在 Proxy 层做统计。

### 4. 解决方案

#### 方案一：本地缓存 (Local Cache) —— **最推荐**
在应用服务器（Client）端增加一级本地缓存（如 Caffeine、Guava Cache）。
- **流程**：请求 -> 本地缓存 -> Redis -> DB。
- **优点**：热点请求直接在 JVM 内部响应，无需网络 IO，性能最高，彻底解放 Redis。
- **缺点**：应用集群内各节点数据可能不一致（需容忍短时间不一致或配合 Pub/Sub 做失效通知）。

#### 方案二：热 Key 拆分 (Key Sharding/Replication)
将一个热 Key 复制多份，分散存储到不同的 Redis 分片上。
- **做法**：将 `hot_key` 变为 `hot_key_0`, `hot_key_1`, ... `hot_key_N`。
- **写操作**：更新时需要同时更新所有副本（成本高）。
- **读操作**：客户端请求时，随机选择一个后缀进行访问（如 `hot_key_` + `random(0, N)`）。
- **适用场景**：读多写少的场景，极大地分散了单节点的读压力。

#### 方案三：读写分离
利用 Redis 主从架构，增加 Slave 节点数量。
- **做法**：主节点负责写，多个从节点负责读。
- **缺点**：成本增加；只能缓解读压力；主从复制存在延迟。## 分布式计数器
INCR
INCRBY

## 底层数据结构
String
List（quicklist）
Set（）
Zset（哈希表dict存储member score的映射关系，跳表skiplist按score排序并保证平均OlogN的查询复杂度、支持范围查询、维护成本比红黑树低）
Hash（ziplist存储，超过512个元素或者任意元素大于64字节转为hashtable，不再回退）
### 核心数据结构
ziplist压缩列表，内存空间连续，减少内存碎片，但是插入和删除时间复杂度On，不适合频繁修改
```txt
[zlbytes][zltail][zllen][entry1][entry2][...][entryN][zlend]

头部信息：
- zlbytes：整个ziplist的字节数
- zltail：最后一个entry的偏移量
- zllen：entry的数量

每个entry的结构：
[previous_entry_length][encoding][content]
- previous_entry_length：前一个entry的长度
- encoding：当前entry的编码方式
- content：实际数据
```

### ZipList vs SkipList：设计哲学与应用场景

#### 1. ZipList (压缩列表)
**核心思想**：
**时间换空间**。通过极致的内存压缩，减少内存碎片和占用，适合小数据量。

**特点**：
- **存储结构**：一块连续的内存空间（类似数组），没有前后指针，而是记录上一个节点的长度来实现反向遍历。
- **内存优化**：紧凑存储，对 CPU 缓存友好（Locality of Reference）。
- **连锁更新（Cascade Update）风险**：
  - 插入或删除节点时，因为需要记录前一个节点的长度（`previous_entry_length`），如果该长度发生变化（如从 1 字节变 5 字节），可能导致后续所有节点的该字段都需要更新，引发连锁反应。
  - **时间复杂度**：查询 $O(N)$，插入/删除平均 $O(N)$，最坏 $O(N^2)$（连锁更新）。

**适用场景**：
- 元素数量少且长度短的对象（如 Hash、List、ZSet 的底层初期实现）。
- 目的：省内存。

---

#### 2. SkipList (跳表)
**核心思想**：
**空间换时间**。通过多层索引结构，实现类似二分查找的高效查询。

**存储结构**：
- 链表加多级索引。最底层包含所有元素，每向上一层抽取部分元素作为索引。
- 每个节点包含：元素值、分值（Score）、后退指针（BW，用于 ZREVRANGE）、以及层级数组（Forward 指针 + 跨度 Span）。

**为什么用跳表而不用红黑树/B+树？**
1. **实现简单**：相比红黑树复杂的旋转平衡逻辑，跳表更容易实现和调试。
2. **范围查询高效**：ZSet 经常需要 `ZRANGE` / `ZREVRANGE`。跳表找到起点后，直接遍历底层链表即可；平衡树则需要复杂的子树遍历。
3. **并发友好**：虽然 Redis 是单线程，但在并发环境下，跳表的局部更新对整体结构锁竞争更小（相比树结构的再平衡）。
4. **内存占用适中**：平均每个节点 1.33 个指针，比平衡树（通常2个指针）更省（但比 ZipList 费）。

**时间复杂度**：
- 查找、插入、删除：平均 $O(\log N)$。

**适用场景**：
- 元素数量多（ZSet 默认 > 128 个）或元素值较大时。
- 目的：高性能排序和范围查找。

#### 总结对比
| 维度 | ZipList | SkipList |
| :--- | :--- | :--- |
| **本质** | 连续内存块（类数组） | 链表 + 多级索引 |
| **设计目标** | **省内存**（CPU 换内存） | **高性能**（内存换 CPU） |
| **查询复杂度** | $O(N)$ | $O(\log N)$ |
| **插入/删除** | $O(N)$（可能连锁更新） | $O(\log N)$ |
| **内存碎片** | 极少 | 较多（尤其是频繁申请节点） |
| **ZSet 场景** | 元素少时使用 | 元素多时自动升级 |

## 持久化
Redis 提供了两种主要的持久化机制，用于在重启时恢复数据。

### 1. RDB (Redis DataBase)
**机制**：
将某个时间点的所有数据生成快照（Snapshot）存储到磁盘上的二进制文件（`dump.rdb`）。

**触发方式**：
- **手动触发**：
  - `SAVE`：阻塞主线程，直到文件生成完毕（生产环境慎用）。
  - `BGSAVE`：Fork 一个子进程在后台生成 RDB 文件，主进程继续处理请求。
- **自动触发**：
  - 配置文件规则（如 `save 900 1`：900秒内有1次修改则触发）。
  - 主从复制时，主节点会自动触发 BGSAVE 发送给从节点。
  - 执行 `SHUTDOWN` 且未开启 AOF 时。

**优点**：
- **恢复快**：文件紧凑，适合大规模数据恢复。
- **高性能**：主进程只需 Fork 子进程，不进行磁盘 I/O。
- **备份方便**：适合冷备（灾难恢复）。

**缺点**：
- **数据丢失风险**：两次快照之间的数据会丢失。
- **耗时耗内存**：数据量大时，Fork 子进程会阻塞主线程（虽短但有影响），且 Copy-on-Write 机制在写操作频繁时会增加内存消耗。

### 2. AOF (Append Only File)
**机制**：
以日志的形式记录每一次**写操作**（命令），重启时重新执行这些命令恢复数据。

**同步策略（刷盘）**：
- `appendfsync always`：每条写命令都同步（最安全，最慢）。
- `appendfsync everysec`：每秒同步一次（默认，性能与安全性的平衡，最多丢1秒数据）。
- `appendfsync no`：由操作系统决定何时同步（最快，不安全）。

**重写机制 (Rewrite)**：
随着时间推移，AOF 文件会越来越大。Redis 提供 `BGREWRITEAOF` 命令，将内存中的数据转化为最小命令集重新写入 AOF 文件（例如将 100 次 `INCR` 变更为 1 次 `SET`），减少文件体积。

**优点**：
- **数据更安全**：默认每秒刷盘，最多丢 1 秒数据。
- **可读性强**：纯文本协议，误删数据（如 FLUSHALL）后，如果未重写，可手动删掉最后一行命令进行恢复。

**缺点**：
- **文件体积大**：通常比 RDB 大。
- **恢复慢**：需要回放所有命令。

### 3. RDB vs AOF 与 混合持久化
| 特性 | RDB | AOF |
| :--- | :--- | :--- |
| **占用空间** | 小（二进制压缩） | 大（文本记录） |
| **恢复速度** | 快 | 慢 |
| **数据安全性** | 容易丢数据 | 安全性高 |
| **性能开销** | Fork 子进程消耗内存/CPU | 频繁 IO 开销 |

**混合持久化 (Redis 4.0+)**：
结合两者优点。AOF 重写时，将当前内存数据以 RDB 格式写入 AOF 文件的开头，后续的增量数据依然以 AOF 格式追加。
- **优点**：快速加载（RDB部分） + 数据更安全（AOF部分）。

## 集群
主从复制
哨兵
集群

## 事务（待定）
Redis事务是指将多个Redis命令打包，然后一次性执行。