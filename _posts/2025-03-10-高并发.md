---
title: 分布式与高并发
tags: Architecture
---

分布式锁、全局唯一ID、限流熔断算法实现
<!--more-->

## 分布式锁
分布式锁是一种用于控制分布式系统中多个进程对共享资源的访问的机制。它可以确保在任何给定时间只有一个进程可以访问共享资源，从而避免数据不一致和资源竞争的问题。
### 分布式锁的设计原则
Redis关于分布式锁的定义：
- 互斥（属于安全性）：在任何给定时刻，只有一个客户端可以持有锁。
- 无死锁（属于有效性）：即使锁定资源的客户端崩溃或被分区，也总是可以获得锁；通常通过超时机制实现。
- 容错性（属于有效性）：只要大多数 Redis 节点都启动，客户端就可以获取和释放锁。
### 基于数据库实现

### 基于Redis实现

### 基于Zookeeper实现


## 分布式系统下的全局唯一ID
可以分为两个大类：
- 类DB的自增ID
- 类snowflak
### UUID
UUID（Universally Unique Identifier）是一种标准的标识符，由128位数字组成，通常表示为32个十六进制数字的字符串。UUID的唯一性由其生成算法保证，不同的UUID之间几乎不可能重复。
#### UUID生成算法
UUID的生成算法基于以下几个因素：
1. 时间戳：使用当前时间的毫秒数作为UUID的一部分。
2. 时钟序列：在同一毫秒内生成多个UUID时，使用时钟序列进行区分。
3. 节点标识符：使用计算机的网络地址作为UUID的一部分。
#### UUID的唯一性
UUID的唯一性由其生成算法保证，不同的UUID之间几乎不可能重复。然而，UUID的生成算法也存在一些问题，例如：
1. 时间戳的唯一性受到系统时钟的影响，可能会出现时间戳回拨的情况。
2. 节点标识符的唯一性受到网络环境的影响，可能会出现节点标识符重复的情况。
#### 总结
优点：
- 本地生成没有网络消耗
缺点：
- 长度过长，容易造成数据库性能瓶颈、不适合高并发场景
- 无序性，无法判断生成ID的先后顺序

### Snowflake算法
第1位占用1bit，其值始终是0，可看做是符号位不使用。第2位开始的41位是时间戳，41-bit位可表示2^41个数，每个数代表毫秒，那么雪花算法可用的时间年限是(1L<<41)/(1000L360024*365)=69 年的时间。中间的10-bit位可表示机器数，即2^10 = 1024台机器，但是一般情况下我们不会部署这么台机器。如果我们对IDC（互联网数据中心）有需求，还可以将 10-bit 分 5-bit 给 IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，具体的划分可以根据自身需求定义。最后12-bit位是自增序列，可表示2^12 = 4096个数。


Snowflake 算法结构（64位）：
- 1位符号位：始终为0
- 41位时间戳：精确到毫秒，可使用69年
- 10位工作机器ID：
  - 5位数据中心ID（0-31）
  - 5位机器ID（0-31）
- 12位序列号：同一毫秒内可生成4096个ID

Snowflake 保证唯一性和有序性的机制：
1. 时间戳保证全局趋势递增
2. 工作机器ID保证不同节点生成的ID不重复
3. 序列号保证同一毫秒内的唯一性
4. 时钟回拨问题解决：
   - 记录上一次的时间戳
   - 发现回拨时等待或抛出异常
   - 使用备用生成器

## 限流算法


### 1. 固定窗口限流算法
> Fixed Window Rate Limiting Algorithm，将时间划分为固定大小的窗口，在每个窗口（单位时间）内限制请求数量。

**工作原理**：
- 将时间划分为固定长度的窗口（如1秒）
- 在每个窗口内维护一个计数器
- 每次请求到达时：
  1. 判断当前时间窗口
  2. 查看计数器是否超过阈值
  3. 未超过则请求通过并计数器+1
  4. 超过则拒绝请求
- 当进入新的时间窗口时，计数器重置为0

**示例代码**：
```java
public class FixedWindowRateLimiter {
    // 时间窗口大小（毫秒）
    private long windowSize;
    // 窗口内允许的最大请求数
    private int maxRequests;
    // 当前窗口的请求计数
    private AtomicInteger count;
    // 当前窗口的开始时间
    private AtomicLong windowStart;

    public FixedWindowRateLimiter(long windowSize, int maxRequests) {
        this.windowSize = windowSize;
        this.maxRequests = maxRequests;
        this.count = new AtomicInteger(0);
        this.windowStart = new AtomicLong(System.currentTimeMillis());
    }

    public boolean tryAcquire() {
        long now = System.currentTimeMillis();
        long currentWindow = windowStart.get();
        // 检查是否需要重置时间窗口
        if (now - currentWindow > windowSize) {
            count.set(0);
            windowStart.set(now);
        }
        // 尝试增加计数
        if (count.get() < maxRequests) {
            count.incrementAndGet();
            return true;
        }
        return false;
    }
}

public class RateLimiterDemo {
    public static void main(String[] args) {
        // 创建一个1秒内最多允许100个请求的限流器
        FixedWindowRateLimiter limiter = new FixedWindowRateLimiter(1000, 100);

        // 模拟请求
        for (int i = 0; i < 150; i++) {
            boolean allowed = limiter.tryAcquire();
            System.out.println("请求-" + i + ": " + (allowed ? "通过" : "被限流"));
        }
    }
}
```

**优点**：
- 实现简单，容易理解
- 内存占用小
- 适合简单场景

**缺点**：
- 临界问题：两个窗口交界处可能突发双倍流量
  > 假设限制是每秒100个请求
  > - 第一个窗口的最后500ms涌入100个请求
  > - 第二个窗口的开始500ms又涌入100个请求
  > - 结果在这1秒内（跨越两个窗口）实际通过了200个请求
  > - 这违背了每秒限制100个请求的初衷
- 突发流量：窗口开始时可能瞬间被占满
- 资源利用不均匀
- 突发流量：窗口开始时可能瞬间被占满
- 资源利用不均匀

使用场景：
- 简单的接口限流
- 并发量不大的场景
- 对突发流量不敏感的场景

## 高并发写请求处理策略：

1. 数据库优化
   - 分库分表：水平拆分、垂直拆分
   - 读写分离：主库写入，从库读取
   - 批量写入：合并多个写操作
   - 索引优化：避免过多索引，合理设计索引
   - 连接池管理：合理配置连接数

2. 缓存策略
   - 写缓存：先写缓存，异步写库
   - 双写一致性：缓存和数据库同步更新
   - 缓存预热：提前加载热点数据
   - 缓存降级：高峰期只更新缓存

3. 异步处理
   - 消息队列：削峰填谷
   - 异步写入：非核心数据延迟写入
   - 事件驱动：解耦业务流程
   - 任务队列：将写操作转为任务执行

4. 架构优化
   - 服务拆分：按业务领域拆分
   - 集群部署：负载均衡
   - 分布式事务：保证数据一致性
   - 熔断降级：保护核心业务

5. 并发控制
   - 分布式锁：避免重复写入
   - 乐观锁：版本号控制
   - 悲观锁：必要时加锁保护
   - 限流：合理控制写入速率

## AI工具